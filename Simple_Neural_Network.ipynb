{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Let's try to compute AND operation using Mathematical function"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "<img src=\"nn_and.PNG\" width=\"50%\" height=\"50%\">\n<p> Credits: Andrew NG Machine Learning </p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def function(x1,x2):\n    #return -30 + x1 * 20 + 20 * x2\n    return -0.5 + x1 * 0.5 + 0.5 * x2\n\ndef sigmoid_function(x):\n    return 1/(1 + math.exp(-1 * x))",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"x1 = 0 and x2 = 0\")\nround(sigmoid_function(function(0,0)))",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": "x1 = 0 and x2 = 0\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"x1 = 0 amd x2 = 1\")\nround(sigmoid_function(function(0,1)))",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "x1 = 0 amd x2 = 1\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"x1 = 1 amd x2 = 0\")\nround(sigmoid_function(function(1,0)))",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": "x1 = 1 amd x2 = 0\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"x1 = 1 amd x2 = 1\")\nround(sigmoid_function(function(1,1)))",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": "x1 = 1 amd x2 = 1\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "1"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### As you have seen above the mathematical function was able to compute and function\n### Let's try to implement a Simple Neural Network with out a hidden layer and check it it's able to compute a AND function by adjusting the weights automatically"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### We will create a neural network with\n- 2 inputs layers\n- 0 hidden layers\n- 1 output layer"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#x inputs\nX = np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])\n\n#x output\ny_output = np.array([0.0,0.0,0.0,1.0])",
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"============input==========\")\nprint(X)\n\nprint(\"===========output==========\")\nprint(y_output)",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "============input==========\n[[0. 0.]\n [0. 1.]\n [1. 0.]\n [1. 1.]]\n===========output==========\n[0. 0. 0. 1.]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.scatter(X[:,0],X[:,1],c=y_output,label=['zero','one'])\nplt.show()",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#instead of using sigmoid we can use check function as well\ndef check(x):\n    return tf.to_float(tf.greater(x,0.5))",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sess = tf.Session()\n\n#Let's call weights of the input layer w and bias be b\nX = tf.convert_to_tensor(X, dtype=tf.float32)\ny_output = tf.reshape(tf.convert_to_tensor(y_output, dtype=tf.float32), [4,1])\nw = tf.Variable(tf.random_normal([2, 1]), dtype=tf.float32,name=\"weights\")\nb = tf.Variable(tf.random_normal([1]),dtype=tf.float32,name=\"bias\")\n\n#output\noutput = tf.sigmoid(tf.add(tf.matmul(X,w),b))\nerror = tf.subtract(y_output, output)\nmse = tf.reduce_mean(tf.square(error))\ndelta = tf.matmul(tf.transpose(X), error)\nadder = tf.add(w, delta)\ntrain = tf.assign(w, adder)\n\n\nsess.run(tf.global_variables_initializer())",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#err, target = 1, 0\nepoch, max_epochs = 0, 1000\n\nwhile epoch < max_epochs:\n    epoch += 1\n    err, _ = sess.run([mse, train])\nprint('epoch:', epoch, 'mse:', err)\n\nWeights = np.array(sess.run(w))\nbias = np.array(sess.run(b))\n\nprint(Weights)\nprint(bias)",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "epoch: 1000 mse: 0.25848317\n[[-0.04475254]\n [-0.04475254]]\n[0.06712872]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_input = np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])\n\ndef sigmoid_function(x):\n    return 1/(1 + np.exp(-1 * x))\nprint(sigmoid_function(np.matmul(X_input,Weights) + bias))\nprint(np.round(sigmoid_function(np.matmul(X_input,Weights) + bias)))",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[0.51677588]\n [0.50559381]\n [0.50559381]\n [0.49440614]]\n[[1.]\n [1.]\n [1.]\n [0.]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sess.close()",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Next we will try to implement the above code using gradient descent optimizers and trying to reduce the loss"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#we will use graph here\n#a default graph even if we don't create a any graph\ngraph1 = tf.Graph()\n#with graph1.as",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#with graph1.as_default():\nX = tf.constant([[0.,0.],[0.,1.],[1.,0.],[1.,1.]], dtype=tf.float32, name = \"X\")\ny_output = tf.constant([0.0,0.0,0.0,1.0], dtype=tf.float32, name=\"y_output\")\n\n#X = tf.constant([[0,0],[0,1],[1,0],[1,1]], dtype=tf.int8, name = \"X\")\n#y_output = tf.constant([0,0,0,1], dtype=tf.int8, name=\"y_output\")\n\nb = 10 * tf.Variable(tf.random_normal([1],stddev = 1.0 , mean=0.0),dtype=tf.float32,name=\"bias\")\n#w = tf.Variable(tf.random_normal([2, 1] ,stddev = 1.0 , mean=0.0), dtype=tf.float32,name=\"weights\")\nw1 = 10 * tf.Variable(tf.random_normal([1,1] ,stddev = 1.0 , mean=0.0), dtype=tf.float32,name=\"weights\")\nw2 = 10 * tf.Variable(tf.random_normal([1,1] ,stddev = 1.0 , mean=0.0), dtype=tf.float32,name=\"weights\")\nw = tf.concat([w1,w2],0)\n\n#output = tf.math.sign(tf.add(tf.matmul(X,w),b))\noutput = tf.sigmoid(tf.add(tf.matmul(X,w),b))\n#mse = tf.subtract(y_output, output)\nerror = tf.subtract(y_output, output)\nmse = tf.reduce_mean(tf.square(error))\noptimizer = tf.train.GradientDescentOptimizer(0.8)\ntrain = optimizer.minimize(mse)",
      "execution_count": 103,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "init = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\nmse_values = 1\nmse_val = []\nmax_epochs = 100\nepochs = 0\nwhile  max_epochs > epochs and mse_values > 0.17:\n#while mse_values > 0.17:\n    #_,mse_values = sess.run()\n    _,mse_values = sess.run([train,mse])\n    mse_val.append(mse_values)\n    #print(mse_values)\n    epochs += 1\nbias = sess.run(b)\n#Weights = np.array([sess.run(w1),sess.run(w2)])\nWeights = np.array(sess.run(w))\n\nprint(bias)\nprint(Weights)\nprint(mse_values)\nprint(epochs)",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[9.049087]\n[[-0.56193495]\n [ 4.354837  ]]\n0.74987876\n100\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_input = np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])\n\ndef sigmoid_function(x):\n    return 1/(1 + np.exp(-1 * x))\nprint(np.matmul(X_input,Weights) + bias)\nprint(sigmoid_function(np.matmul(X_input,Weights) + bias))\nnp.round(sigmoid_function(np.matmul(X_input,Weights) + bias))\n",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 9.04908657]\n [13.40392351]\n [ 8.48715162]\n [12.84198856]]\n[[0.99988252]\n [0.99999849]\n [0.99979394]\n [0.99999735]]\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 105,
          "data": {
            "text/plain": "array([[1.],\n       [1.],\n       [1.],\n       [1.]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sess.close()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "with tf.Session(graph=graph1) as sess:\n    sess.run(init)\n    mse_val = []\n    for step in range(20):\n        #_,mse_values = sess.run()\n        sess.run([train,mse,error,output])\n        #mse_val.append(mse_values)\n        #print(mse_values)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "help (tf.random_normal)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "round(sigmoid_function(0.4))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}